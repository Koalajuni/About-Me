# About-Me

Hey there! ğŸ‘‹ I'm Hyoun Jun Lee, a dynamic software engineer with a fusion of Business Administration expertise and an Integrated Major in Artificial Intelligence. I'm on a mission to leverage my unique background and hands-on experience in the world of computer science and am eager to contribute to the world's cutting-edge technological ecosystem.

**ğŸ“ Academic Background:**

Business Administration: Equipped with a solid foundation in data interpretation and analysis, I've honed my analytical skills to address user needs through technology.
Integrated Major in AI: My journey into the realm of artificial intelligence was sparked by a desire to harmonize my fascination with business and technology.
 
**ğŸ’¡ Innovation & Problem-Solving:**

Generative AI Hackathon: Participated in Primer's inaugural event, developing a calendar-based event recommendation program using Open AIâ€™s LLM model. Demonstrated a solution-oriented mindset and technical acumen.

**ğŸš€ Entrepreneurial Spirit:**

B2C Calendar App: Co-founded a mobile application with AI-driven event recommendations using Google's Flutter SDK. Launched on both Android and iOS platforms, reaching 2000 users with a 30% weekly retention rate. Proven adaptability and solution-focused approach.

**ğŸŒ Vision for the Future:**

I am driven by a desire to be a catalyst for positive change, leveraging technology to address complex challenges and deepen my understanding of computer science.

ğŸ¤ Excited about contributing to innovative projects and collaborating with like-minded professionals.

Sincerely,
Hyoun Jun Lee




# Papers To Read (ì½ì–´ì•¼í•  ë…¼ë¬¸) 

### LLM Architecture 
- https://arxiv.org/pdf/2001.08361 (Scaling Laws for Neural Language Models) - 2020 
- https://arxiv.org/pdf/2501.00663 (Titan Learning to Memorize at Test Time) - 2024


### Transformers (Deep Learning)
- https://arxiv.org/pdf/1409.0473 (Neural Translation) - 2014 (Done)
- https://arxiv.org/pdf/1706.03762 (Attention is all you need) - 2017 (Done) 
- Google: https://arxiv.org/pdf/1810.04805 (BERT)
- OpenAI: https://arxiv.org/pdf/2005.14165 (ChatGPT)

### Generative Adversarial Nets
- https://arxiv.org/pdf/1406.2661 (GAN) - 2014

### Diffusion
- https://arxiv.org/abs/2106.09685 (LORA) - 2021
- https://arxiv.org/abs/2405.05252 (Diffusion + Attention) - 2024

### Computer Vision 
- https://arxiv.org/pdf/1506.02640 (Yolo) - 2015

### Benchmark 
- https://arxiv.org/pdf/2310.06770 (SWE Bench) auto coder ë§Œë“¤ê¸° ìœ„í•´

------------------------------------------------------------------------------------------------
# Papers I've Read and Analyzed (ì½ê³  ë¶„ì„í•œ ë…¼ë¬¸ +  url) 
ì•„ë˜ ë…¼ë¬¸ë“¤ì€ Harvard Computer Science êµìˆ˜ê°€ ì‘ì„±í•œ How to read a Research Paperë¥¼ ì°¸ê³ í•´ ìš”ì•½í•œ ë…¼ë¬¸ë“¤ì´ë‹¤. 
https://www.eecs.harvard.edu/~michaelm/postscripts/ReadPaper.pdf

### Transformers (Deep Learning) 
- https://docs.google.com/document/d/1mespiXkhgEbwd7S-g1Fht41-cTWHk_6r29Je6tPIzVU/edit?usp=sharing (Neural Translation) - 2014
- https://docs.google.com/document/d/1ern24AZZr-bBPWHGdTTg2ATjmJ-tnVLQtzCKOLUyC0I/edit?usp=sharing (Attention is all you need) - 2017
